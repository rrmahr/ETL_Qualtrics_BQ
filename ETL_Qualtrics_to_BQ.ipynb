{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297db12c",
   "metadata": {},
   "source": [
    "# ETL Pipeline from Qualtrics to Google BigQuery\n",
    "This is a simple extract, transform, load pipeline to extract data from a Qualtrics survey, transform / process the data to meet database requirements and load the data to a Google BigQuery dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab2c02",
   "metadata": {},
   "source": [
    "## TOC\n",
    "* [1. Extract Data from Qualtrics](#1)\n",
    "* [2. Transform Data](#2)\n",
    "    * [2a. Create Data Dictionary](#2a)\n",
    "    * [2b. Transform Response Data](#2b)\n",
    "* [3. Load Data to BigQuery](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries & view function for qgrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "import io\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "\n",
    "#For Qualtrics API\n",
    "from QualtricsAPI.Survey import Responses #python package that loads responses as pandas dataframe\n",
    "import os\n",
    "import requests\n",
    "\n",
    "#For BigQuery Import\n",
    "from datetime import datetime\n",
    "from google.cloud import bigquery\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7cf3d",
   "metadata": {},
   "source": [
    "## 1. Extract Data From Qualtrics <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac285f",
   "metadata": {},
   "source": [
    "### Enter API Credentials <a class=\"anchor\" id=\"1a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tokens and survey ID here -- need Qualtrics API access -- replace xxxx below with credentials and survey ID\n",
    "token=\"xxxx\"\n",
    "data_center=\"xxxx\"\n",
    "directory_id=\"xxxx\"\n",
    "survey=\"xxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initital QualtricsAPI setup\n",
    "from QualtricsAPI.Setup import Credentials\n",
    "\n",
    "#Create an instance of Credentials\n",
    "c = Credentials()\n",
    "\n",
    "#Call the qualtrics_api_credentials() method\n",
    "c.qualtrics_api_credentials(token, data_center, directory_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993f150",
   "metadata": {},
   "source": [
    "### Extract Survey Responses and Survey Design using API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f53f1",
   "metadata": {},
   "source": [
    "#### Survey Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c029d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create an instance\n",
    "r = Responses()\n",
    "\n",
    "#Store responses in a pandas dataframe\n",
    "df = r.get_survey_responses(survey)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2325a0",
   "metadata": {},
   "source": [
    "#### Survey Details\n",
    "* Will be used to develop data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc81265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting user Parameters - this may throw an error after it is set, comment out, if so\n",
    "apiToken = os.environ[token] \n",
    "dataCenter = os.environ[data_center]\n",
    "\n",
    "baseUrl = \"https://{0}.qualtrics.com/API/v3/surveys/{1}\".format(os.environ['data_center'], survey)\n",
    "headers = {\n",
    "    \"x-api-token\": os.environ['token'],\n",
    "    }\n",
    "\n",
    "response = requests.get(baseUrl, headers=headers)\n",
    "data = response.json()\n",
    "\n",
    "#Set data to result level\n",
    "data = data['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473d819",
   "metadata": {},
   "source": [
    "## 2. Transform Data <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000577db",
   "metadata": {},
   "source": [
    "### 2a. Create Data Dictionary <a class=\"anchor\" id=\"2a\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416fe800",
   "metadata": {},
   "source": [
    "#### Save data in dependencies folder to use in data_dictionary_dev.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07df99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data (survey details)\n",
    "with open('Dependencies/data.pkl', 'wb') as handle:\n",
    "    pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#save df (survey responses)\n",
    "df.to_pickle('Dependencies/responses_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b7565",
   "metadata": {},
   "source": [
    "#### Run data_dictionary_dev.py\n",
    "* This will create a data dictionary to accompany the response data\n",
    "* Additional details on the data dictionary development process can be found here: https://github.com/rrmahr/Qualtrics-Data-Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1197d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output is data_dict_df\n",
    "%run Dependencies/data_dictionary_dev.py\n",
    "\n",
    "#Uncomment to inspect\n",
    "#data_dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd4576",
   "metadata": {},
   "source": [
    "### 2b. Transform Response Data<a class=\"anchor\" id=\"2b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46685d72",
   "metadata": {},
   "source": [
    "#### Drop Unwanted Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop first two rows with labels and QID's\n",
    "df = df.drop([0,1]).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487b97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Delete unnecessary columns / personally identifiable information (PII) to protect respondent privacy\n",
    "cols_to_delete = [\"RecipientLastName\",\"RecipientFirstName\",\"RecipientEmail\",\"LocationLatitude\",\"LocationLongitude\",\n",
    "                  \"IPAddress\"]\n",
    "\n",
    "#Delete from df\n",
    "df = df.drop(columns = cols_to_delete)\n",
    "\n",
    "#Delete from data dictionary\n",
    "data_dict_df = data_dict_df[~data_dict_df['Var_Name'].isin(cols_to_delete)].copy().reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08399d23",
   "metadata": {},
   "source": [
    "#### Assign Data Types based on Data Dictionary\n",
    "Need to assign data types prior to additional data processing / transformations to avoid errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Integers\n",
    "Int_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='INT']['Var_Name']:\n",
    "    if i not in Int_List:\n",
    "        Int_List.append(i)\n",
    "\n",
    "#Convert just to numeric for now not to INT to avoid errors when creating new vars based on existing INT vars\n",
    "df[Int_List] = df[Int_List].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "#Floats\n",
    "Float_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='FLOAT']['Var_Name']:\n",
    "    if i not in Float_List:\n",
    "        Float_List.append(i)\n",
    "\n",
    "df[Float_List] = df[Float_List].astype(float)\n",
    "\n",
    "\n",
    "#String\n",
    "String_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='STRING']['Var_Name']:\n",
    "    if i not in String_List:\n",
    "        String_List.append(i)\n",
    "     \n",
    "df[String_List] = df[String_List].astype(str)\n",
    "for i in String_List:\n",
    "    df[i] = df[i].replace('nan',np.NaN, regex=False)\n",
    "\n",
    "#Timestamp\n",
    "Timestamp_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='TIMESTAMP']['Var_Name']:\n",
    "    if i not in Timestamp_List:\n",
    "        Timestamp_List.append(i)\n",
    "\n",
    "for i in Timestamp_List:\n",
    "    df[i] = pd.to_datetime(df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90c393",
   "metadata": {},
   "source": [
    "#### Rename Variables for Consistency with database requirements / naming conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Qualtrics 'Duration (in seconds)' var has spaces in name which could present issues\n",
    "cols_to_rename = {'Duration (in seconds)': 'duration_seconds'}\n",
    "df = df.rename(columns = cols_to_rename)\n",
    "\n",
    "#rename in data dictionary as well\n",
    "data_dict_df = data_dict_df.replace({\"Var_Name\": cols_to_rename})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c855c8",
   "metadata": {},
   "source": [
    "#### Create Additional Variables for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9418186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example: Age Groups\n",
    "conditions = [(df['age'] < 18),\n",
    "              ((df['age'] >= 18) & (df['age']<= 26)),\n",
    "              ((df['age'] >= 27) & (df['age']<= 42)),\n",
    "              ((df['age'] >= 43) & (df['age']<= 58)),\n",
    "              ((df['age'] >= 59) & (df['age']<= 68)),\n",
    "              (df['age'] > 68)]\n",
    "\n",
    "values = [1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "df['age_groups'] = np.select(conditions, values, default = np.nan)\n",
    "df['age_groups'] = df['age_groups'].apply(pd.to_numeric)\n",
    "\n",
    "#Add to data dictionary\n",
    "data_dict_add = {\n",
    "    'Var_Name' : ['age_groups','age_groups','age_groups','age_groups','age_groups','age_groups'],\n",
    "    'Var_Label' : ['Age groups based on generation','Age groups based on generation','Age groups based on generation',\n",
    "                   'Age groups based on generation','Age groups based on generation','Age groups based on generation'],\n",
    "    'Value' : [1,2,3,4,5,6],\n",
    "    'Value_Label' : ['Under 18 years','Gen Z 18-26', 'Millennials 27-42','Gen X 43-58','Boomers 59-68','Other - Senior 69+'],\n",
    "    'Data_Type' : ['INT','INT','INT','INT','INT','INT']}\n",
    "    \n",
    "data_dict_add_df = pd.DataFrame(data_dict_add)\n",
    "data_dict_df = pd.concat([data_dict_df,data_dict_add_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c28269",
   "metadata": {},
   "source": [
    "#### Conduct Additional Transformations\n",
    "There are many data transformations that can occur here, some examples include:\n",
    "* Merging separate datasets with additional respondent information on ResponseId, or with additional project/client level information\n",
    "* Recoding values to match database coding conventions\n",
    "* Identifying and cleaning fraudulent responses\n",
    "* Transposing/melting/pivoting data to be at appropriate level for database integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adbb61",
   "metadata": {},
   "source": [
    "#### Assign Data Types Again\n",
    "* AFTER all transformations are complete, need to assign data types to df again as well as to data dictionary.\n",
    "* This step is necessary to ensure all new variables have appropriate data type for data base integration as well as to assign to integer data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330857da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df\n",
    "\n",
    "#Integers\n",
    "Int_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='INT']['Var_Name']:\n",
    "    if i not in Int_List:\n",
    "        Int_List.append(i)\n",
    "\n",
    "#Now convert to 'Int64'\n",
    "df[Int_List] = df[Int_List].apply(pd.to_numeric)\n",
    "df[Int_List] = df[Int_List].astype('Int64')\n",
    "\n",
    "\n",
    "#Floats\n",
    "Float_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='FLOAT']['Var_Name']:\n",
    "    if i not in Float_List:\n",
    "        Float_List.append(i)\n",
    "\n",
    "df[Float_List] = df[Float_List].astype(float)\n",
    "\n",
    "\n",
    "#String\n",
    "String_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='STRING']['Var_Name']:\n",
    "    if i not in String_List:\n",
    "        String_List.append(i)\n",
    "     \n",
    "df[String_List] = df[String_List].astype(str)\n",
    "for i in String_List:\n",
    "    df[i] = df[i].replace('nan',np.NaN, regex=False)\n",
    "\n",
    "#Timestamp\n",
    "Timestamp_List = []\n",
    "for i in data_dict_df[data_dict_df['Data_Type']=='TIMESTAMP']['Var_Name']:\n",
    "    if i not in Timestamp_List:\n",
    "        Timestamp_List.append(i)\n",
    "\n",
    "for i in Timestamp_List:\n",
    "    df[i] = pd.to_datetime(df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01568ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dictionary\n",
    "\n",
    "#Float\n",
    "data_dict_df['Value'] = data_dict_df['Value'].apply(pd.to_numeric, errors='coerce')\n",
    "data_dict_df['Value'] = data_dict_df['Value'].astype(float)\n",
    "\n",
    "\n",
    "#String\n",
    "String_List = ['Var_Name','Var_Label','Value_Label','Data_Type','Question_Type']\n",
    "\n",
    "data_dict_df[String_List] = data_dict_df[String_List].astype(str)\n",
    "for i in String_List:\n",
    "    data_dict_df[i] = data_dict_df[i].replace('nan',np.NaN, regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefc642",
   "metadata": {},
   "source": [
    "## 3. Load Data to BigQuery <a class=\"anchor\" id=\"3\"></a>\n",
    "For simplicity, the code below will create a new table in the \"survey_responses\" dataset and in the \"data_dictionaries\" dataset in a Google BigQuery project with the current date and time as part of the table name to avoid duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7cb76",
   "metadata": {},
   "source": [
    "#### Set API Credentials\n",
    "* Below uses service account private key files to obtain credentials for the service account\n",
    "* For more information see Google's API documentation here: https://googleapis.dev/python/google-auth/1.7.0/user-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70a00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Input service account private key file to connect to BigQuery\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'Dependencies/private_key_file.json') \n",
    "\n",
    "scoped_credentials = credentials.with_scopes(\n",
    "    ['https://www.googleapis.com/auth/cloud-platform'])\n",
    "\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id,)\n",
    "\n",
    "#credentials.project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510f00b",
   "metadata": {},
   "source": [
    "#### Load Survey Responses to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ca12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#enter the BigQuery dataset name\n",
    "dataset_id = 'survey_responses'\n",
    "\n",
    "#name table to create\n",
    "table_id = 'survey_responses' + '_' + str(datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"))\n",
    "\n",
    "#Create the table in BigQuery\n",
    "client.create_table(f\"{credentials.project_id}.{dataset_id}.{table_id}\")\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True\n",
    "\n",
    "# load the df into the table in BigQuery\n",
    "job = client.load_table_from_dataframe(df, table_ref, job_config=job_config) # Make an API request to Load\n",
    "\n",
    "#allow the job to complete\n",
    "job.result()\n",
    "\n",
    "# Prints number of rows loaded into BigQuery table if job worked\n",
    "print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, dataset_id, table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fa35d3",
   "metadata": {},
   "source": [
    "#### Load Data Dictionary to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc66f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter the BigQuery dataset name\n",
    "dataset_id = 'data_dictionaries'\n",
    "\n",
    "#name table to create\n",
    "table_id = 'data_dictionary' + '_' + str(datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"))\n",
    "\n",
    "#Create the table in BigQuery\n",
    "client.create_table(f\"{credentials.project_id}.{dataset_id}.{table_id}\")\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "table_ref = dataset_ref.table(table_id)\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.autodetect = True\n",
    "\n",
    "# load the df into the table in BigQuery\n",
    "job = client.load_table_from_dataframe(data_dict_df, table_ref, job_config=job_config) # Make an API request to Load\n",
    "\n",
    "#allow the job to complete\n",
    "job.result()\n",
    "\n",
    "# Prints number of rows loaded into BigQuery table if job worked\n",
    "print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, dataset_id, table_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
